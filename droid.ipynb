{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import bagit\n",
    "import posixpath\n",
    "from collections import Counter\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to give us some rough whole of collection statistics about metrics like format distribution, duplication and modified dates. It does this by looping through a directory, hoovering up droid csv files (either created using Droid or Siegfried with the -droid switch). \n",
    "\n",
    "Assumptions:\n",
    "Each package is in a bagit structure.\n",
    "Each package has a droid csv report,with a name ending with 'droid.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droid_sniff(file):\n",
    "    'this will help us determine whether a given file is a droid csv'\n",
    "    if file.endswith('csv'):\n",
    "        with open(file) as f:\n",
    "            sample = f.read(16)\n",
    "            if 'PARENT_ID' in sample:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will read each droid csv report into a Pandas dataframe. It also appends a checksum column from the checksums in the bag manifest, as we don't use the checksum option in Droid usually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def norm_path(path):\n",
    "    try:\n",
    "        path = posixpath.normpath('data'+path.split('data')[1])\n",
    "        return path\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "directory = 'corpus'\n",
    "frames = []\n",
    "bag_names = []\n",
    "for root, _, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        f_path = os.path.join(root, file)\n",
    "        if droid_sniff(f_path):\n",
    "            bag = bagit.Bag(root.split('data')[0])\n",
    "            droid = pd.read_csv(f_path, parse_dates=['LAST_MODIFIED'], index_col=False)\n",
    "            #I had some empty droid csvs in the corpus for some reason, so:\n",
    "            if len(droid) > 0:\n",
    "                #Here, we're going to append the hashes from the bag to the dataframe. \n",
    "                #Unnecessary if you use the hash function in droid\n",
    "                droid['NORM_PATH'] = droid['FILE_PATH'].apply(norm_path)\n",
    "                hashes = pd.Series(\n",
    "                    {posixpath.normpath(k) : v.get('sha256') for k, v in bag.payload_entries().items()}, name='SHA256')\n",
    "                frame = droid.join(hashes, on='NORM_PATH')\n",
    "                #where droid isn't sure about a format, it creates lines for each possible match\n",
    "                #so we're just going to keep the first one\n",
    "                #frame.drop_duplicates(subset='URI', keep='first', inplace=True)\n",
    "                frames.append(frame)\n",
    "                bag_names.append(os.path.split(bag.path)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then concatenate the dataframes. We'll also create a subset for unique files by dropping duplicates on the checksum column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def fstring(x):\n",
    "    s = '{0} {1} {2}'.format(*x)\n",
    "    if s == 'nan nan nan':\n",
    "        s = 'Unidentified'\n",
    "    else:\n",
    "        s = s.replace('nan', '').strip()\n",
    "    return s\n",
    "    \n",
    "\n",
    "result = pd.concat(frames, keys=bag_names, names=['bag', 'index'], sort=False)\n",
    "#We're going to concatenate a couple of columns to create a distinct string for each format and version\n",
    "result['FORMAT_STRING'] = result[['PUID', 'FORMAT_NAME', 'FORMAT_VERSION']].apply(fstring, axis=1)\n",
    "files = result[result['TYPE'] == 'File']\n",
    "unique_files = files.drop_duplicates(subset='SHA256')\n",
    "\n",
    "\n",
    "def f(item):\n",
    "    return files.xs(item, level=\"bag\")\n",
    "\n",
    "itemlist = sorted(set([x[0] for x in files.index.tolist()]))\n",
    "interact(f, item=itemlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_filter(hash):\n",
    "    return files[files['SHA256'] == hash]\n",
    "interact(hash_filter, hash='e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to graph some data. Our semi-obvious first step is to make some pie charts of the format distribution. We'll do this by number of files and total file sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "f_numbers  = unique_files['FORMAT_STRING'].value_counts(dropna=False)\n",
    "sizes = unique_files.fillna('unidentified').groupby('FORMAT_STRING')['SIZE'].sum().sort_values(ascending=False)\n",
    "sizes = sizes.reset_index()\n",
    "f_numbers = f_numbers.reset_index()\n",
    "\n",
    "fig = {\n",
    "    \"data\": [{\"values\": sizes['SIZE'], \"labels\": sizes['FORMAT_STRING'], \"hoverinfo\": 'label+percent', \"showlegend\": False,\n",
    "              \"domain\": {\"column\": 1}, \"name\": \"Formats by size\", \"textinfo\": 'value', \"hole\": .4, \"type\": \"pie\"},\n",
    "            {\"values\": f_numbers['FORMAT_STRING'], \"labels\": f_numbers['index'], \"hoverinfo\": 'label+percent', \"showlegend\": False,\n",
    "             \"textinfo\": 'value', \"domain\": {\"column\": 0}, \"name\": \"Formats by size\", \n",
    "             \"textinfo\": 'value', \"hole\": .4, \"type\": \"pie\"}], \"layout\": {\"legend\": {\"orientation\": \"h\"},\n",
    "            \"title\": \"File formats\", \"grid\": {\"rows\": 1, \"columns\": 2}\n",
    "}}\n",
    "iplot(fig, filename=\"formats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = unique_files['FORMAT_NAME'].value_counts()\n",
    "fc.values[:] = 0\n",
    "pc = unique_files['PUID'].value_counts()\n",
    "c = fc.append(pc)\n",
    "f = unique_files.drop_duplicates(subset='PUID').set_index('PUID')['FORMAT_NAME']\n",
    "sun = pd.concat([c, f], axis=1, sort=False)\n",
    "sun.columns = ['count', 'parent']\n",
    "\n",
    "\n",
    "trace = go.Sunburst(\n",
    "    labels=sun.index,\n",
    "    parents=sun['parent'],\n",
    "    values=sun['count'],\n",
    "    #branchvalues='total',\n",
    "    outsidetextfont = {\"size\": 20, \"color\": \"#377eb8\"},\n",
    "    marker = {\"line\": {\"width\": 2}},\n",
    ")\n",
    "layout = go.Layout(\n",
    "    margin = go.layout.Margin(t=0, l=0, r=0, b=0, )\n",
    ")\n",
    "iplot(go.Figure([trace], layout), filename='format_spread')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = files['LAST_MODIFIED'].dt.strftime('%Y').value_counts().sort_index()[:25]\n",
    "uyears = unique_files['LAST_MODIFIED'].dt.strftime('%Y').value_counts().sort_index()[:25]\n",
    "uyears = uyears.reset_index()\n",
    "years = years.reset_index()\n",
    "data = [\n",
    "    go.Scatter(x=uyears['index'], y=uyears['LAST_MODIFIED'], name='Unique files'),\n",
    "    go.Scatter( x=years['index'], y=years['LAST_MODIFIED'], name='Total files')]\n",
    "\n",
    "iplot(data, filename='pandas-time-series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = files['LAST_MODIFIED'].dt.strftime('%Y-%m').value_counts().sort_index()\n",
    "uyears = unique_files['LAST_MODIFIED'].dt.strftime('%Y-%m').value_counts().sort_index()\n",
    "uyears = uyears.reset_index()\n",
    "years = years.reset_index()\n",
    "uyears = uyears[uyears['index'] < '2014-01']\n",
    "years = years[years['index'] < '2014-01']\n",
    "data = [\n",
    "    go.Scatter(x=uyears['index'], y=uyears['LAST_MODIFIED'], name='Unique files'),\n",
    "    go.Scatter(x=years['index'], y=years['LAST_MODIFIED'], name='Files')]\n",
    "\n",
    "iplot(data, filename='pandas-time-series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "f = 'FORMAT_STRING'\n",
    "for puid in files[f].unique():\n",
    "    filtered = unique_files[unique_files[f] == puid]\n",
    "    filtered = filtered['LAST_MODIFIED'].dt.strftime('%Y-%m').value_counts().sort_index()\n",
    "    filtered = filtered.reset_index()\n",
    "    filtered = filtered[filtered['index'] < '2014-01']\n",
    "    data.append(go.Scatter(x=filtered['index'], y=filtered['LAST_MODIFIED'], name=puid, mode='markers'))\n",
    "layout = go.Layout(\n",
    "    legend={'orientation': 'v'})\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='pandas-time-series')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
